#welcome to the sad life

#set-up
library(caret)
library(dplyr)
library(e1071)
library(MASS)
library(mlbench)
library(psych)

#defined an self programmed function here#

#Starting out
hDisease<-read.csv("heart-disease.csv",fileEncoding="UTF-8-BOM")
summary(hDisease) #need to change target to factor
hDisease<-hDisease%>%mutate(dis=factor(ifelse(target==1,"Disease","Healthy")))
hDcat<-hDisease[,c(2,3,6,7,9,11:15)] #df of categorical data and relevant factors
hDcont<-hDisease[,c(1,2,4,5,8,10,14,15)] #df of continuous data and relevant factors

#Explore individual relationship between variables and heart disease
#confusion matrices (or maybe bar) and chi-squared for cat, bar/scatter and t-test for cont (haven't tried yet)

#Cat variables, chi-squared for T/F(nominal), bar charts of ordinal data
table(hDisease$sex,hDisease$dis) #Gender proportion, can do chi-squared
chisq.test(hDisease$sex,hDisease$dis,correct=FALSE) # p = 1*10^-6, implies significant difference
#night be some problem in the data set cause implies prevalence higher in women (sex=0), not like IRL?

ggplot(hDisease,aes(fill=dis,x=cp))+geom_bar(stat="bin",binwidth=0.5)
#observe higher portion of disease with reported chest pain, normalise to proportionalilty?
chisq.test(hDisease$cp,hDcat$dis,correct=FALSE) #significant difference -> not independent

table(hDisease$fbs,hDisease$dis)
chisq.test(hDisease$fbs,hDisease$dis,correct=FALSE) #sememingly no relation dependence between fbs and HD

table(hDisease$restecg,hDisease$dis)
chisq.test(hDisease$restecg,hDisease$dis,correct=TRUE) #returns a sig diff but low pop of restecg=2 maybe thorwing off the results
ggplot(hDisease,aes(fill=dis,x=restecg))+geom_bar(stat="bin",binwidth=0.5) #from here looks like no (strong) relation

table(hDisease$exang,hDisease$dis)
chisq.test(hDisease$exang,hDisease$dis,correct=FALSE) #indicates exang is a -ve predictor of HD?

ggplot(hDisease,aes(fill=dis,x=slope))+geom_bar(stat="bin",binwidth=0.5)
#proportion of HD increases with level of slope

ggplot(hDisease,aes(fill=dis,x=ca))+geom_bar(stat="bin",binwidth=0.5)
#Inverse for ca

ggplot(hDisease,aes(fill=dis,x=thal))+geom_bar(stat="bin",binwidth=0.5) #unclear

#Cont variables, box to a summary of the differences between cont var in healthy vs diseased, consider histogram too?
ggplot(hDisease,aes(age,sex,col=dis))+geom_point()#not very helpful
ggplot(hDisease,aes(dis,age))+geom_boxplot() #median age of healthy is higher, less dispersed
ggplot(hDisease,aes(dis,trestbps))+geom_boxplot() #doesn't look significantly diff

ggplot(hDisease,aes(dis,chol))+geom_boxplot() #slightly higher for healthy but disease has more extreme high outliers?
hDHeal<-hDisease%>%filter(dis %in% c("Healthy"))
mean(hDHeal$chol) #251.087
hDDis<-hDisease%>%filter(dis %in% c("Disease"))
mean(hDDis$chol) #242.2303, but why lower?

ggplot(hDisease,aes(dis,thalach))+geom_boxplot() #thalach higher of diseased, less dispersed -> stronger relation?
ggplot(hDisease,aes(dis,oldpeak))+geom_boxplot() # much lower for disease, weaker heart?

#correlation between cont variables
#First check which are worth exploring
pairs.panels(hDcont[,-c(2,7,8)],method="pearson",hist.col="red",pch=21,bg=c("green","blue")[(hDcont$dis)],density=TRUE,ellipses=FALSE)
#In general, no strong correlation between varaiables (age col acting weird)

hDcontH<-hDcont%>%filter(dis %in% c("Healthy"))
pairs.panels(hDcontH[,-c(2,7,8)],method="pearson",hist.col="red",pch=21,bg=c("green","blue")[(hDcontH$dis)],density=TRUE,ellipses=FALSE)
#no relation

hDcontD<-hDcont%>%filter(dis %in% c("Disease"))
pairs.panels(hDcontD[,-c(2,7,8)],method="pearson",hist.col="red",pch=21,bg=c("green","blue")[(hDcontD$dis)],density=TRUE,ellipses=FALSE)
#age/thalach worth looking into

#can also just try feeding inputs to a chosen, sig variable

#classification part
set.seed(1999)
train.index<-sample(1:nrow(hDisease),size=nrow(hDisease)*0.8)
train.set<-hDisease[train.index,]
test.set<-hDisease[-train.index,]
#kNN
#logistic regression
#svm (pretty sure don't have to normalise? Original can get 88% accuracy, I only got 80%)
dis.svmL<-svm(dis~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=train.set,kernel="linear") #linear svm
pred.svmL<-predict(dis.svmL,newdata=test.set[,1:13])
table(pred.svmL,test.set$dis) #favours false -ve
mean(pred.svmL==test.set$dis) #about 80% accuracy

dis.svm.polT<-tune.svm(dis~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=train.set,kernel="polynomial",cost=10^(-2:2),gamma=c(0.1,0.5,1,2,3),degree=4)
dis.svmP<-dis.svm.polT$best.model #poly kern SVM
pred.svmP<-predict(dis.svmP,newdata=test.set[,1:13])
table(pred.svmP,test.set$dis) #also favours false -ve
mean(pred.svmP==test.set$dis) # slightly worse than linear

dis.svm.radT<-tune.svm(dis~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=train.set,kernel="radial",cost=10^(-2:2),gamma=c(0.1,0.5,1,2,3))
dis.svmR<-dis.svm.radT$best.model #rad kern SVM
pred.svmR<-predict(dis.svmR,newdata=test.set[,1:13])
table(pred.svmR,test.set$dis)
mean(pred.svmR==test.set$dis) #same as linear

dis.svm.sigT<-tune.svm(dis~age+sex+cp+trestbps+chol+fbs+restecg+thalach+exang+oldpeak+slope+ca+thal,data=train.set,kernel="sigmoid",cost=10^(-2:2),gamma=c(0.1,0.5,1,2,3),coef0=c(-2:2))
dis.svmS<-dis.svm.sigT$best.model #sigmoid kern SVM
pred.svmS<-predict(dis.svmS,newdata=test.set[,1:13])
table(pred.svmS,test.set$dis) 
mean(pred.svmS==test.set$dis) #slightly worse than linear
#conclusion, different kernels don't produce different results, use linear for less comp load

#comparison and analysis

